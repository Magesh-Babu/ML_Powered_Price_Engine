{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "def parse_quote_pdf(pdf_path):\n",
    "    \"\"\"Parse a quote PDF and return a list of dicts for each quote line.\"\"\"\n",
    "    # Open the PDF and extract text from the first page\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[0]\n",
    "        text = page.extract_text()\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Identify the start of the table and the end (marked by \"Verktygskostnad:\")\n",
    "    idx_tool = None\n",
    "    idx_table_start = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if idx_table_start is None and (\"Profil nr\" in line or (line.strip().startswith(\"Profil\") and \"kg/m\" in line)):\n",
    "            idx_table_start = i\n",
    "        if line.strip().startswith(\"Verktygskostnad:\"):\n",
    "            idx_tool = i\n",
    "            break\n",
    "\n",
    "    if idx_table_start is None or idx_tool is None:\n",
    "        return []  # return empty if parsing failed\n",
    "    \n",
    "    #print(f\"Table starts at line {idx_table_start}, ends at line {idx_tool}\")\n",
    "\n",
    "    # Determine where the actual data lines begin (after the header lines)\n",
    "    idx_data_start = idx_table_start\n",
    "    for j in range(idx_table_start, idx_tool):\n",
    "        # The last header line often contains \"Årsvolym\" or \"SEK\" or ends with \"g:\"\n",
    "        if \"Årsvolym\" in lines[j] or lines[j].strip() == \"SEK\" or lines[j].strip().endswith(\"g:\"):\n",
    "            idx_data_start = j + 1\n",
    "\n",
    "    # Extract table data lines, filtering out header artifacts\n",
    "    data_lines = []\n",
    "    for k in range(idx_data_start, idx_tool):\n",
    "        line_clean = lines[k].strip()\n",
    "        if not line_clean or any(line_clean.startswith(h) for h in [\"Profil\", \"Kund ref.\", \"Vikt\", \"Pris/st\", \"Kap\", \"SEK\"]):\n",
    "            continue\n",
    "\n",
    "        parts = line_clean.split()\n",
    "        if len(parts) >= 7:\n",
    "            # We assume last 6 parts are numeric values, first is profile name\n",
    "            profile_name = \" \".join(parts[:-6])\n",
    "            row = [\n",
    "                profile_name,\n",
    "                parts[-6],  # Vikt\n",
    "                parts[-5],  # Längd\n",
    "                parts[-4],  # Kap+truml\n",
    "                parts[-3],  # Årsvolym\n",
    "                parts[-2],  # Pris\n",
    "                parts[-1],  # Legering\n",
    "            ]\n",
    "            data_lines.append(row)   \n",
    "        \n",
    "    #print(\"Data lines extracted:\", data_lines)\n",
    "\n",
    "    # Extract metadata fields from lines outside the table\n",
    "    metadata = {}\n",
    "    for line in lines:\n",
    "        line_stripped = line.strip()\n",
    "        if line_stripped.startswith(\"Datum:\"):\n",
    "            metadata[\"Datum\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Vår referens:\"):\n",
    "            metadata[\"Vår referens\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Er referens:\"):\n",
    "            metadata[\"Er referens\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Kund:\"):\n",
    "            metadata[\"Kund\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Verktygskostnad:\"):\n",
    "            metadata[\"Verktygskostnad\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Legering:\"):\n",
    "            # Store separately to use if table rows don't include alloy\n",
    "            metadata[\"Legering_all\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Toleranser:\"):\n",
    "            metadata[\"Toleranser\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Ytbehandling:\"):\n",
    "            metadata[\"Ytbehandling\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Lev. längd:\"):\n",
    "            metadata[\"Lev. längd\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Lev. villkor:\"):\n",
    "            metadata[\"Lev. villkor\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Lev. tid:\"):\n",
    "            metadata[\"Lev. tid\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"NOT:\"):\n",
    "            metadata[\"NOT\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Betalningsvillkor:\"):\n",
    "            metadata[\"Betalningsvillkor\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Giltighet:\"):\n",
    "            metadata[\"Giltighet\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Allmänna villkor:\"):\n",
    "            metadata[\"Allmänna villkor\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "        elif line_stripped.startswith(\"Råvara:\"):\n",
    "            metadata[\"Råvara (euro/kg)\"] = line_stripped.split(\":\", 1)[1].strip()\n",
    "\n",
    "    #print(\"Metadata extracted:\", metadata)\n",
    "\n",
    "    # Parse each data line into fields and combine with metadata\n",
    "    rows = []\n",
    "    for parts in data_lines:\n",
    "        #parts = re.split(r'\\s{2,}', line.strip())\n",
    "        # Assign each column from the split parts\n",
    "        profil = parts[0] if len(parts) > 0 else \"\"\n",
    "        vikt = parts[1] if len(parts) > 1 else \"\"\n",
    "        längd = parts[2] if len(parts) > 2 else \"\"\n",
    "        kap_truml = parts[3] if len(parts) > 3 else \"\"\n",
    "        årsvolym = parts[4] if len(parts) > 4 else \"\"\n",
    "        pris_st = parts[5] if len(parts) > 5 else \"\"\n",
    "        legering = parts[6] if len(parts) > 6 else metadata.get(\"Legering_all\", \"\")\n",
    "        # Combine into one record (dict)\n",
    "        row = {\n",
    "            \"Profil_namn\": profil,\n",
    "            \"Vikt (kg/m)\": vikt,\n",
    "            \"Längd (m)\": längd,\n",
    "            \"Kap + truml (Pris/st)\": kap_truml,\n",
    "            \"ca antal (Årsvolym st)\": årsvolym,\n",
    "            \"Pris (kr/st) SEK\": pris_st,\n",
    "            \"Legering\": legering\n",
    "        }\n",
    "        # Add metadata fields to the record\n",
    "        for key, value in metadata.items():\n",
    "            # Use \"Legering_all\" only if \"Legering\" field was empty\n",
    "            if key == \"Legering_all\":\n",
    "                continue\n",
    "            row[key] = value\n",
    "        rows.append(row)\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage: parsing all PDFs and combining results\n",
    "all_quotes = []\n",
    "for file_num in range(1, 51):\n",
    "    file_name = f\"/Users/mageshbabu/Desktop/Projects/project_odens/Test files/PdfNAP ({file_num}).pdf\"\n",
    "    rows = parse_quote_pdf(file_name)\n",
    "    all_quotes.extend(rows)\n",
    "\n",
    "# `all_quotes` now contains a list of dictionaries, each representing one quote line with metadata.\n",
    "# You can further convert this to CSV or DataFrame as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert list of dictionaries to DataFrame\n",
    "df_all_quotes = pd.DataFrame(all_quotes)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = \"all_quotes_extracted.csv\"\n",
    "df_all_quotes.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✅ Saved {len(df_all_quotes)} rows to {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
